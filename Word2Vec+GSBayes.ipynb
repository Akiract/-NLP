{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    # review = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    # print(words)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    '''\n",
    "    1. 将评论文章，按照句子段落来切分(所以会比文章的数量多很多)\n",
    "    2. 返回句子列表，每个句子由一堆词组成\n",
    "    '''\n",
    "    review = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    # raw_sentences 句子段落集合\n",
    "    raw_sentences = tokenizer.tokenize(review)\n",
    "    # print(raw_sentences)\n",
    "    \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            # 获取句子中的词列表\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "root_dir = \"C:/Users/andea/Desktop/STARed-Kernel/github上找的kaggle实例\"\n",
    "train = pd.read_csv('%s/%s' % (root_dir, 'labeledTrainData.tsv'), header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('%s/%s' % (root_dir, 'testData.tsv'), header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = nltk.data.load(r'tokenizers\\\\punkt\\\\english.pickle',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "sentences = []\n",
    "for i, review in enumerate(train[\"review\"]):\n",
    "    # print(i, review)\n",
    "    sentences += review_to_sentences(review, tokenizer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(267188,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train[\"review\"]))\n",
    "print(np.shape(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "# 模型参数\n",
    "num_features = 300    # 词向量维度                    \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # 并行线程数\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练模型中...\n",
      "训练完成\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 训练模型\n",
    "print(\"训练模型中...\")\n",
    "model = Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count=min_word_count, \\\n",
    "            window=context, sample=downsampling)\n",
    "print(\"训练完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存模型...\n",
      "保存结束\n"
     ]
    }
   ],
   "source": [
    "print('保存模型...')\n",
    "model.init_sims(replace=True)\n",
    "model_name = \"%s/%s\" % (root_dir, \"300features_40minwords_10context\")\n",
    "model.save(model_name)\n",
    "print('保存结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    '''\n",
    "    对段落中的所有词向量进行取平均操作\n",
    "    '''\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "\n",
    "    # Index2word包含了词表中的所有词，为了检索速度，保存到set中\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "\n",
    "    # 取平均\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#给定一个文本列表，每个文本由一个词列表组成，返回每个文本的词向量平均值\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    '''\n",
    "    给定一个文本列表，每个文本由一个词列表组成，返回每个文本的词向量平均值\n",
    "    '''\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
    "\n",
    "    for review in reviews:\n",
    "        if counter % 5000 == 0:\n",
    "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with all this stuff going down at the moment with mj i ve started listening to his music watching the odd documentary here and there watched the wiz and watched moonwalker again maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent moonwalker is part biography part feature film which i remember going to see at the cinema when it was originally released some of it has subtle messages about mj s feeling towards the press and also the obvious message of drugs are bad m kay br br visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him br br the actual feature film bit when it finally starts is only on for minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord why he wants mj dead so bad is beyond me because mj overheard his plans nah joe pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno maybe he just hates mj s music br br lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence also the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene br br bottom line this movie is for people who like mj on one level or another which i think is most people if not then stay away it does try and give off a wholesome message and ironically mj s bestest buddy in this movie is a girl michael jackson is truly one of the most talented people ever to grace this planet but is he guilty well with all the attention i ve gave this subject hmmm well i don t know because people can be different behind closed doors i know this for a fact he is either an extremely nice but stupid guy or one of the most sickest liars i hope he is not the latter \n",
      "\n",
      "naturally in a film who s main themes are of mortality nostalgia and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones however there is a craftsmanship and completeness to the film which anyone can enjoy the pace is steady and constant the characters full and engaging the relationships and interactions natural showing that you do not need floods of tears to show emotion screams to show fear shouting to show dispute or violence to show anger naturally joyce s short story lends the film a ready made structure as perfect as a polished diamond but the small changes huston makes such as the inclusion of the poem fit in neatly it is truly a masterpiece of tact subtlety and overwhelming beauty\n"
     ]
    }
   ],
   "source": [
    "# 预处理数据\n",
    "label = train['sentiment']\n",
    "train_data = []\n",
    "for i in range(len(train['review'])):\n",
    "    train_data.append(' '.join(review_to_wordlist(train['review'][i])))\n",
    "test_data = []\n",
    "for i in range(len(test['review'])):\n",
    "    test_data.append(' '.join(review_to_wordlist(test['review'][i])))\n",
    "\n",
    "# 预览数据\n",
    "print(train_data[0], '\\n')\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-5e56b802d2b1>:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec, model[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 5000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 20000 of 25000\n",
      "(25000, 300)\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "trainDataVecs = getAvgFeatureVecs(train_data, model, num_features)\n",
    "print(np.shape(trainDataVecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(C=1.0) # (alpha=1.0, class_prior=None, fit_prior=True)\n",
    "# 为了在预测的时候使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.fit(trainDataVecs,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-5e56b802d2b1>:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec, model[word])\n"
     ]
    }
   ],
   "source": [
    "%time testDataVecs = getAvgFeatureVecs(test_data, model, num_features)\n",
    "print(np.shape(testDataVecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_LR.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
